import{_ as t,E as p,Z as o,$ as c,a0 as n,a3 as s,a1 as e,a4 as i}from"./framework-64cb0dab.js";const l="/assets/quick-tutorial-1-3eecb59a.png",r="/assets/quick-tutorial-2-57effcf2.png",d="/assets/quick-tutorial-3-9d6cfe63.png",u="/assets/quick-tutorial-4-d0a10ebe.png",k="/assets/quick-tutorial-5-bc045d29.png",m="/assets/quick-tutorial-6-46741e6a.png",h="/assets/quick-tutorial-7-6bc2c386.png",v="/assets/quick-tutorial-8-7d7a1ebe.png",_="/assets/quick-tutorial-9-aa3228b7.png",b="/assets/quick-tutorial-10-abdc0eaf.png",g={},y=n("h1",{id:"快速教程",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#快速教程","aria-hidden":"true"},"#"),s(" 快速教程")],-1),q=n("p",null,"您已经安装好了 Crawlab 并或许迫不及待的想开始使用它。但在此之前，建议您过一遍这篇快速教程。它将介绍一些基础知识，并让您熟悉 Crawlab 的部分主要功能。",-1),f=n("h2",{id:"介绍",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#介绍","aria-hidden":"true"},"#"),s(" 介绍")],-1),x={href:"https://www.zyte.com/",target:"_blank",rel:"noopener noreferrer"},w={href:"http://quotes.toscrape.com/",target:"_blank",rel:"noopener noreferrer"},C={href:"https://scrapy.org/",target:"_blank",rel:"noopener noreferrer"},S={class:"hint-container warning"},N=n("p",{class:"hint-container-title"},"注意",-1),E=n("p",null,[s("我们假设您已经根据 "),n("a",{href:"../quick-start"},"快速开始"),s(" 在本地安装好了 Crawlab。如果没有，请参考 "),n("a",{href:"../quick-start"},"快速开始"),s(" 将其安装在您本地。")],-1),V={href:"https://www.python.org/",target:"_blank",rel:"noopener noreferrer"},I={href:"https://pip.pypa.io/en/stable/installation/",target:"_blank",rel:"noopener noreferrer"},P=i(`<h2 id="创建爬虫" tabindex="-1"><a class="header-anchor" href="#创建爬虫" aria-hidden="true">#</a> 创建爬虫</h2><p>首先，我们将创建一个 Scrapy 项目，咱们从安装 Scrapy 开始。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>pip <span class="token function">install</span> scrapy
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>然后，创建一个名叫 <code>scrapy_quotes</code> 的 Scrapy 项目。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>scrapy startproject scrapy_quotes
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>现在您应该可以看到新创建爬虫的目录结构。</p><p>然后执行下面命令生成一个新的爬虫。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">cd</span> scrapy_quotes
scrapy genspider quotes quotes.toscrape.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>爬虫目录结构应该跟下面类似。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>scrapy_quotes
├── scrapy.cfg
└── scrapy_quotes
    ├── __init__.py
    ├── items.py
    ├── middlewares.py
    ├── pipelines.py
    ├── settings.py
    └── spiders
        ├── __init__.py
        └── quotes.py
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>打开 <code>scrapy_quotes/scrapy_quotes/spiders/quotes.py</code> 并将如下内容替换掉原文件内容。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># scrapy_quotes/scrapy_quotes/spiders/quotes.py</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QuotesSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&#39;quotes&#39;</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;quotes.toscrape.com&#39;</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;http://quotes.toscrape.com/&#39;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> quote <span class="token keyword">in</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">&quot;div.quote&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> <span class="token punctuation">{</span>
                <span class="token string">&#39;text&#39;</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">&quot;span.text::text&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">&#39;author&#39;</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">&quot;small.author::text&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">&#39;tags&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;,&#39;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">&quot;div.tags &gt; a.tag::text&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token punctuation">}</span>

        next_page_url <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">&quot;li.next &gt; a::attr(href)&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> next_page_url <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span>next_page_url<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>然后打开文件 <code>scrapy_quotes/scrapy_quotes/settings.py</code> 并将如下代码加入到文件最后。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 加入到 scrapy_quotes/scrapy_quotes/settings.py 最后</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&#39;crawlab.CrawlabPipeline&#39;</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们现在已经创建好可集成到 Crawlab 的 Scrapy 爬虫，然后我们将上传它至 Crawlab。</p><h2 id="上传爬虫" tabindex="-1"><a class="header-anchor" href="#上传爬虫" aria-hidden="true">#</a> 上传爬虫</h2><p>现在打开浏览器并导航到 <code>http://localhost:8080</code>，并输入默认 用户名/密码 <code>admin/admin</code>.</p><p>然后导航到 <code>Spiders</code> 页面，并点击在左上方 <code>New Spider</code>，打开创建对话框。</p><p>在对话框中，输入如下信息并点击 <code>Confirm</code>，创建新爬虫。</p><ol><li>Name: <code>scrapy_quotes</code></li><li>Command: <code>scrapy crawl quotes</code></li></ol><p><img src="`+l+'" alt="create-spider"></p><p>现在我们已经在 Crawlab 中创建好爬虫了，然后我们需要上传爬虫文件。</p><p>点击爬虫名称链接或者右侧名称为 <code>View</code> 的蓝色搜索图标，导航至详情页。</p><p><img src="'+r+'" alt=""></p><p>在详情页中，点击 <code>Files</code> 标签，导航到文件编辑器，然后点击导航条上 <code>Upload Files</code> 按钮。</p><p><img src="'+d+'" alt=""></p><p>点击 <code>Click to Select Folder to Upload</code> 按钮，选择先前创建的 Scrapy 爬虫所在目录，并点击 <code>Confirm</code> 上传爬虫。</p><p><img src="'+u+'" alt=""></p><p>现在您应该能在左侧导航栏看到已上传的文件和目录。您可以尝试操作它，例如点击展开目录、双击文件打开文件。</p><p><img src="'+k+'" alt=""></p><h2 id="运行爬虫" tabindex="-1"><a class="header-anchor" href="#运行爬虫" aria-hidden="true">#</a> 运行爬虫</h2><p>运行爬虫非常简单。</p><p>我们点击名称为 <code>Run</code> 的播放图标按钮，保持默认设置点击 <code>Confirm</code>。</p><p><img src="'+m+'" alt=""></p><h2 id="查看任务" tabindex="-1"><a class="header-anchor" href="#查看任务" aria-hidden="true">#</a> 查看任务</h2><p>很好！我们已经触发了一个爬虫任务，现在我们应该能够在 <code>Tasks</code> 标签中查看它。我们点击 <code>Tasks</code> 标签查看一下。</p><p><img src="'+h+'" alt=""></p><p>该任务正在运行，我们可以点击右侧的 <code>View</code> 按钮查看它的详情。</p><p>我们能够点击 <code>Logs</code> 标签来查看实时任务日志。</p><p><img src="'+v+'" alt=""></p><p>随着爬虫抓取数据，我们能够点击 <code>Data</code> 标签查看已抓取到的数据。</p><p><img src="'+_+'" alt=""></p><h2 id="爬虫统计数据" tabindex="-1"><a class="header-anchor" href="#爬虫统计数据" aria-hidden="true">#</a> 爬虫统计数据</h2><p>如果我们退回到 <code>Spiders</code> 页面，我们应该能看到爬虫的统计数据</p><p><img src="'+b+'" alt=""></p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结" aria-hidden="true">#</a> 总结</h2><p>这里我们小结一下，我们已经通过一个简单的流程在 Crawlab 上运行了一个 Scrapy 爬虫。</p><ol><li>在本地创建 Scrapy 项目</li><li>在 Crawlab 上创建爬虫</li><li>上传爬虫文件</li><li>触发任务</li><li>在 Crawlab 上查看实时日志、已抓取到的数据以及爬虫统计数据</li></ol><h2 id="下一步" tabindex="-1"><a class="header-anchor" href="#下一步" aria-hidden="true">#</a> 下一步</h2><p>这个快速教程让您能够基本了解 Crawlab 并掌握一些基础的使用方法，例如监控爬虫任务日志、查看抓取到的数据。但您需要清楚，Crawlab 不仅限于这些功能，它还包含许多其他的强大功能，例如节点管理、Git 集成以及 依赖安装，这些可能都是您感兴趣的。您可以查看其他章节来学习如何使用那些功能。</p>',50);function L(T,j){const a=p("ExternalLinkIcon");return o(),c("div",null,[y,q,f,n("p",null,[s("本次教程中，我们将创建一个网络爬虫，以抓取 "),n("a",x,[s("Zyte"),e(a)]),s(" (Scrapy 背后的公司) 提供的 "),n("a",w,[s("模拟网站"),e(a)]),s(" 上的名人名言。接着，我们将上传这个爬虫到 Crawlab，然后运行爬虫来抓取名人名言列表。最后，我们会在 Crawlab 中可视化的查看抓取到的数据。")]),n("p",null,[s("我们将采用的框架是 "),n("a",C,[s("Scrapy"),e(a)]),s("。它是 Python 编写的最受欢迎的爬虫框架，使用起来非常方便，同时也具备很多强大的功能。")]),n("div",S,[N,E,n("p",null,[s("由于我们使用的是 Scrapy，请保证在进行任何操作前您已经安装了 "),n("a",V,[s("Python"),e(a)]),s(" (>=3.6) 以及模块管理工具 "),n("a",I,[s("pip"),e(a)]),s("。")])]),P])}const F=t(g,[["render",L],["__file","index.html.vue"]]);export{F as default};
