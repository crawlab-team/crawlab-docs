import{_ as l,E as a,Z as r,$ as n,a0 as e,a3 as d,a1 as i,a2 as t,a4 as h}from"./framework-64cb0dab.js";const s={},p=e("h1",{id:"爬虫",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#爬虫","aria-hidden":"true"},"#"),d(" 爬虫")],-1),_=e("em",null,"项目",-1),u=e("div",{class:"hint-container warning"},[e("p",{class:"hint-container-title"},"注意"),e("p",null,[e("em",null,"爬虫"),d(" 这个概念在 Crawlab 非常重要，因此我们强烈推荐您仔细阅读这一章节。")])],-1),m=e("h2",{id:"典型流程",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#典型流程","aria-hidden":"true"},"#"),d(" 典型流程")],-1),f=e("p",null,"以下是用户在 Crawlab 操作爬虫的典型流程。",-1),x=h('<h2 id="创建爬虫" tabindex="-1"><a class="header-anchor" href="#创建爬虫" aria-hidden="true">#</a> 创建爬虫</h2><ol><li>导航到 <code>爬虫</code> 页面，再点击左上方的 <code>新建爬虫</code> 按钮</li><li>输入 <code>名称</code>、<code>执行命令</code> 等相关信息</li><li>点击 <code>确认</code></li></ol><p><code>执行命令</code> 是爬虫运行时的基础命令，例如 <code>scrapy crawl myspider</code>，相当于在运行爬虫时执行的 bash/shell 命令。</p><p><code>增量同步文件</code> 是指是在爬虫运行时，是否对爬虫程序的文件进行增量同步，而不是每次都下载全部文件。打开后，可以节省爬虫文件下载时间。</p><p><code>自动安装依赖</code> 是指在爬虫运行时，是否自动安装爬虫所需的依赖包（例如 <code>requirements.txt</code> 中的依赖包）。（该功能仅限专业版）</p><h2 id="上传爬虫" tabindex="-1"><a class="header-anchor" href="#上传爬虫" aria-hidden="true">#</a> 上传爬虫</h2><p>有几种上传爬虫文件的方式。</p><h3 id="上传目录" tabindex="-1"><a class="header-anchor" href="#上传目录" aria-hidden="true">#</a> 上传目录</h3><ol><li>导航到爬虫详情页</li><li>点击 <code>文件</code> 标签</li><li>点击导航条上的 <code>上传文件</code> 按钮</li><li>选择 <code>目录</code></li><li>点击 <code>点击选择目录上传</code></li><li>选择爬虫文件所在目录</li><li>点击 <code>确认</code></li></ol><h3 id="上传文件" tabindex="-1"><a class="header-anchor" href="#上传文件" aria-hidden="true">#</a> 上传文件</h3><ol><li>导航到爬虫详情页</li><li>点击 <code>文件</code> 标签</li><li>点击导航条上的 <code>上传文件</code> 按钮</li><li>选择 <code>文件</code></li><li>拖拽爬虫文件到放置区，或直接点击放置区并选择爬虫文件</li><li>点击 <code>确认</code></li></ol><h3 id="上传文件-拖拽" tabindex="-1"><a class="header-anchor" href="#上传文件-拖拽" aria-hidden="true">#</a> 上传文件 (拖拽)</h3><ol><li>导航到爬虫详情页</li><li>点击 <code>文件</code> 标签</li><li>拖拽爬虫文件或目录到左侧导航栏的目录里</li></ol><h2 id="运行爬虫" tabindex="-1"><a class="header-anchor" href="#运行爬虫" aria-hidden="true">#</a> 运行爬虫</h2><p>您可以根据以下步骤来运行爬虫</p><ol><li>如果您在爬虫详情页，点击导航条上名为 <code>运行</code> 的播放按钮</li><li>如果您在 <code>爬虫列表</code> 页面，点击右侧名为 <code>运行</code> 的播放按钮</li><li>选择合适的爬虫运行设置</li><li>点击 <code>确认</code></li></ol><p>之类是爬虫运行设置的解释。</p><ul><li><code>执行命令</code>: 将被实际运行的 cmd/bash/shell 基础命令</li><li><code>执行参数</code>: 被传入 <code>执行命令</code> 的参数</li><li><code>模式</code>: 运行模式，默认为 <code>随机节点</code>.</li><li><code>优先级</code>: 任务优先级，默认为 5</li></ul><h2 id="实体关系" tabindex="-1"><a class="header-anchor" href="#实体关系" aria-hidden="true">#</a> 实体关系</h2>',19);function b(w,C){const c=a("RouterLink"),o=a("Mermaid");return r(),n("div",null,[p,e("p",null,[d("在 Crawlab 中，爬虫是网络爬虫程序的基本单位。您可以将其看作一个爬虫软件项目，它由代码文件组成，例如 Scrapy 项目。请注意，这里提到的 "),_,d(" 与 Crawlab 中的基础概念 "),i(c,{to:"/zh/guide/project/"},{default:t(()=>[d("项目")]),_:1}),d(" 是不同的。")]),u,m,f,i(o,{id:"mermaid-17",code:"eJxLL0osyFDwCeJyjH7aMfvp7l3PO9a8mLk6VkFX107BKfrJjq4nexZAxbicwKLO0S/2T3ixsAcm6gwWdYl+Nn/p8zndz3dPfjZvTiwXAKZgLGY="}),x,i(o,{id:"mermaid-204",code:"eJxljLsNgCAQQHunuNi7gLW1MdEFUC6IImcOqGR4hWgj9fsgd1ooFkcFMJ5aIkOMTUMXDEwbLh5aqGc0ZJUDT3WhTcLtyeFgXUnHZUUZDCZjFVnIwYt7khmlGMjm/it+f89aKeRncQNGCjjt"})])}const j=l(s,[["render",b],["__file","index.html.vue"]]);export{j as default};
