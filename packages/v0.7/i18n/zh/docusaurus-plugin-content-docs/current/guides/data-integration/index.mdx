---
sidebar_position: 6
title: 数据集成
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 数据集成

您可以通过 Crawlab SDK 将爬虫集成到 Crawlab 平台，从而在网页界面中可视化查看爬取结果。

Crawlab SDK 支持多种主流爬虫框架（如 Scrapy）和编程语言（包括 Python、Node.js、Go 和 Java）。

:::info
Crawlab Python SDK ([crawlab-sdk](https://pypi.org/project/crawlab-sdk)) 已预装在 Crawlab 的基础镜像中。在 Crawlab 的 Docker 环境中可直接使用。
:::

## 基础用法

以下代码示例展示了如何用不同编程语言保存基础数据项。该数据项为包含键值对 `hello: crawlab` 的字典，执行后数据将存入数据库并在 Crawlab 网页界面中展示。

<Tabs defaultValue="python">
  <TabItem value="python" label="Python">
    ```python
    from crawlab import save_item

    # 保存字典格式数据项
    save_item({'hello': 'crawlab'})
    ```
  </TabItem>
  <TabItem value="node" label="Node.js">
    ```javascript
    const { saveItem } = require('@crawlab/sdk');
    
    // 保存对象格式数据项
    saveItem({'hello': 'crawlab'})
    ```
    :::info
    Node.js 支持需要 **Crawlab 专业版**。
    :::
  </TabItem>
  <TabItem value="go" label="Go">
    ```go
    package main

    import "github.com/crawlab-team/crawlab-sdk-go"

    func main() {
      // 保存 Map 格式数据项
      crawlab.SaveItem(map[string]interface{}{
        "hello": "crawlab",
      })
    }
    ```
    :::info
    Go 语言支持需要 **Crawlab 专业版**。
    :::
  </TabItem>
  <TabItem value="java" label="Java">
    ```java
    import io.crawlab.sdk.CrawlabSdk;
    import java.util.HashMap;

    public class Main {
      public static void main(String[] args) {
        // 保存 HashMap 格式数据项
        CrawlabSdk.saveItem(new HashMap<String, Object>() {{
          put("hello", "crawlab");
        }});
      }
    }
    ```
    :::info
    Java 支持需要 **Crawlab 专业版**。
    :::
  </TabItem>
</Tabs>

## Scrapy 集成

[Scrapy](https://scrapy.org) 是 Python 生态中流行的网页爬虫框架，适合高效、可扩展的爬取任务。

集成 Scrapy 到 Crawlab 非常简单，只需在 `settings.py` 中添加 `crawlab.CrawlabPipeline` 即可：
```python
ITEM_PIPELINES = {
  'crawlab.CrawlabPipeline': 888,
}
```

## 更多示例

Crawlab 可轻松集成其他爬虫框架，更多详细示例请参考：[示例文档](/docs/category/examples)。