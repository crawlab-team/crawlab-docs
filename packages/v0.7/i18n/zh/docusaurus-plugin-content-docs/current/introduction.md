---
sidebar_position: 1
title: 介绍
slug: /
---

# 介绍

如果您已经知道什么是Crawlab以及它的用途，您可以直接前往[快速开始](./getting-started/quick-start.md)
或[安装](./getting-started/installation.md)来安装并开始使用Crawlab。

如果您不熟悉Crawlab，您可以按顺序阅读下面的部分以更深入地了解Crawlab。

## 什么是Crawlab？

Crawlab是一个强大的**网络爬虫管理平台**，可以运行用多种编程语言（包括Python、Go、Node.js、Java、C#）开发的网络爬虫和蜘蛛，以及包括Scrapy、Colly、Selenium、Puppeteer在内的框架。它用于运行、管理和监控网络爬虫，特别是在生产环境中，可追溯性、可扩展性和稳定性是主要关注因素。

## 背景与历史

自2019年3月发布以来，Crawlab项目一直在持续开发，并经历了多次重大版本更新。最初的设计目的是解决在需要协调和执行大量蜘蛛时的管理问题。随着许多改进和新功能的更新，Crawlab在开发者社区中越来越受欢迎，尤其是在网络爬虫工程师中。

[变更日志](https://github.com/crawlab-team/crawlab/blob/master/CHANGELOG.md)

## 谁可以使用Crawlab？

- **网络爬虫工程师**。通过将网络爬虫程序集成到Crawlab中，您可以专注于抓取和解析逻辑，而不是浪费太多时间编写通用模块，如任务队列、存储、日志记录、通知等。
- **运维工程师**。Crawlab对运维工程师的主要好处在于部署的便利性（无论是爬虫程序还是Crawlab本身）。Crawlab支持使用Docker和Kubernetes轻松安装。
- **数据分析师**。能够编写代码的数据分析师（例如Python）可以开发网络爬虫程序（例如Scrapy），并将它们上传到Crawlab。然后让Crawlab处理所有其他脏活，它会自动为您收集数据。
- **其他人**。从技术上讲，每个人都可以享受Crawlab提供的自动化带来的便利和简单。尽管Crawlab擅长运行网络爬虫任务，但它也可以用于其他类型的任务，如数据处理和自动化。

## 主要功能

### 核心组件
💻 **节点管理**  
- 在分布式系统中注册和控制多个节点  
- 实时节点监控和资源使用跟踪  

🕷️ **蜘蛛操作**  
- 多语言蜘蛛支持（Python/Node.js/Go/Java）  
- 框架集成（Scrapy/Colly/Selenium/Puppeteer）  
- Git版本控制与自动部署  
- 在线代码编辑器与文件管理  

📋 **任务管理**  
- 分布式任务调度与队列  
- 实时日志与执行监控  
- 详细统计与历史记录  

### 关键能力
📦 **依赖管理**  
- Python/Node.js包安装  
- 自动依赖解析  

🔔 **通知系统**  
- 任务完成时的电子邮件通知  
- 支持Webhook集成  

👥 **团队协作**  
- 多用户访问控制  
- 基于角色的权限  

### 基础设施
🌐 **基于Web的界面**  
- 响应式仪表板  
- 跨平台兼容性  

🐳 **部署灵活性**  
- 云原生架构  
- 横向扩展能力