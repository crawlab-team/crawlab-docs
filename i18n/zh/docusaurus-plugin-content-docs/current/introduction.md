---
sidebar_position: 1
title: 介绍
slug: /
---

# 介绍

如果您已经了解 Crawlab 的功能和用途，可以直接前往[快速开始](./getting-started/quick-start.md)或[安装指南](./getting-started/installation.md)进行安装和使用。

如果您还不熟悉 Crawlab，请继续阅读以下内容以了解更多信息。

## 什么是 Crawlab？

Crawlab 是一个强大的**网络爬虫管理平台**，能够运行使用 Python、Go、Node.js、Java、C# 等语言开发的爬虫程序，支持 Scrapy、Colly、Selenium、Puppeteer 等主流框架。它专门用于在生产环境中运行、管理和监控网络爬虫，特别关注可追溯性、可扩展性和稳定性。

## 背景与历史

Crawlab 项目自 2019 年 3 月发布以来持续开发，经历了多个主要版本迭代。最初设计目的是为了解决大量爬虫程序协调执行的管控问题。经过多次改进和功能更新，Crawlab 在开发者社区中越来越受欢迎，特别是在爬虫工程师群体中。

[更新日志](https://github.com/crawlab-team/crawlab/blob/master/CHANGELOG.md)

## 适用人群

- **爬虫工程师**：通过将爬虫程序集成到 Crawlab，可以专注于爬取和解析逻辑，无需浪费时间编写任务队列、存储、日志、通知等通用模块
- **运维工程师**：Crawlab 提供 Docker 和 Kubernetes 的便捷部署方式，简化爬虫程序和平台本身的部署工作
- **数据分析师**：掌握编程技能（如 Python）的数据分析师可以开发爬虫程序（如 Scrapy）并上传到 Crawlab，剩余工作将全部由平台自动完成
- **其他用户**：原则上任何人都能享受 Crawlab 带来的自动化便利。虽然擅长运行爬虫任务，但也可用于数据处理等其他类型的自动化任务

## 主要特性

### 核心功能
💻 **节点管理**  
- 在分布式系统中注册和控制多个节点  
- 实时节点监控与资源使用追踪  

🕷️ **爬虫操作**  
- 支持多语言爬虫（Python/Node.js/Go/Java）
- 框架集成（Scrapy/Colly/Selenium/Puppeteer）
- Git 版本控制与自动部署
- 在线代码编辑器与文件管理

📋 **任务管理**  
- 分布式任务调度与队列管理  
- 实时日志与执行监控  
- 详细统计与历史记录  

### 关键能力
📦 **依赖管理**  
- Python/Node.js 包安装  
- 自动依赖解析  

🔔 **通知系统**  
- 任务完成邮件通知  
- Webhook 集成支持  

👥 **团队协作**  
- 多用户访问控制  
- 基于角色的权限管理  

### 基础设施
🌐 **Web 界面**  
- 响应式仪表盘  
- 跨平台兼容性  

🐳 **灵活部署**  
- 云原生架构  
- 水平扩展能力 