import{_ as c,Z as l,$ as p,a0 as n,a1 as a,a2 as e,a3 as i,a4 as t,G as r}from"./framework-1b68163c.js";const d={},u=n("h1",{id:"crawlab-ai-sdk",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#crawlab-ai-sdk","aria-hidden":"true"},"#"),a(" Crawlab AI SDK")],-1),h={href:"https://www.crawlab.cn/en/ai",target:"_blank",rel:"noopener noreferrer"},m=t(`<h2 id="installation" tabindex="-1"><a class="header-anchor" href="#installation" aria-hidden="true">#</a> Installation</h2><p>Users can install the SDK using the following command:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>pip <span class="token function">install</span> crawlab-ai
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="authentication" tabindex="-1"><a class="header-anchor" href="#authentication" aria-hidden="true">#</a> Authentication</h2>`,4),b={href:"https://www.crawlab.cn/en",target:"_blank",rel:"noopener noreferrer"},v=t(`<p>Once you have obtained the API token, you can set it as an environment variable in your application:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">CRAWLAB_TOKEN</span><span class="token operator">=</span><span class="token operator">&lt;</span>your-api-token<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Or, you can set it with CLI:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai config <span class="token parameter variable">-t</span> <span class="token operator">&lt;</span>your-api-token<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="usage-as-cli" tabindex="-1"><a class="header-anchor" href="#usage-as-cli" aria-hidden="true">#</a> Usage as CLI</h2><p>The SDK can be used as a command-line interface (CLI) tool. The CLI tool provides a set of commands to interact with the Crawlab AI platform.</p><h3 id="crawl-a-webpage" tabindex="-1"><a class="header-anchor" href="#crawl-a-webpage" aria-hidden="true">#</a> Crawl a Webpage</h3><p>You can crawl a webpage using the SDK as CLI as follows:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai crawl <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>-t <span class="token punctuation">{</span>article,list<span class="token punctuation">}</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>-o OUTPUT<span class="token punctuation">]</span> <span class="token operator">&lt;</span>url<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>The <code>-t</code> option specifies the type of content to extract, which can be either <code>article</code> or <code>list</code>. The <code>-o</code> option specifies the output path for the extracted content. For type of <code>article</code>, the output will be in JSON format, while for <code>list</code>, the output type will be in CSV. If the output path is not specified, the content will be printed to the console.</p><p>For example, to extract an article from a webpage, you can run the following command:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai crawl <span class="token parameter variable">-t</span> article https://www.example.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>To extract a list of items from a webpage, you can run the following command:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai crawl <span class="token parameter variable">-t</span> list <span class="token parameter variable">-o</span> output.csv https://www.example.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="code-generation" tabindex="-1"><a class="header-anchor" href="#code-generation" aria-hidden="true">#</a> Code Generation</h3><p>You can generate code snippets for extracting content from a webpage using the SDK as CLI as follows:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai codegen <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>-t <span class="token punctuation">{</span>article,list<span class="token punctuation">}</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>-o OUTPUT<span class="token punctuation">]</span> <span class="token operator">&lt;</span>url<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>The <code>-t</code> option specifies the type of content to extract, which can be either <code>article</code> or <code>list</code>. The <code>-o</code> option specifies the output path for the generated code. If the output path is not specified, the code will be printed to the console.</p><p>For example, to generate code for extracting an article from a webpage, you can run the following command:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai codegen <span class="token parameter variable">-t</span> article https://www.example.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>To generate code for extracting a list of items from a webpage, you can run the following command:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai codegen <span class="token parameter variable">-t</span> list <span class="token parameter variable">-o</span> output.py https://www.example.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="usage-as-python-library" tabindex="-1"><a class="header-anchor" href="#usage-as-python-library" aria-hidden="true">#</a> Usage as Python Library</h2><p>You can also use the SDK as a Python library in your application.</p><h3 id="extracting-list-content" tabindex="-1"><a class="header-anchor" href="#extracting-list-content" aria-hidden="true">#</a> Extracting List Content</h3><p>Here is an example of how to use the SDK to extract list content from a webpage:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> crawlab_ai <span class="token keyword">import</span> read_list

<span class="token comment"># Define the URL</span>
url <span class="token operator">=</span> <span class="token string">&quot;https://example.com&quot;</span>

<span class="token comment"># Get the data without specifying fields</span>
df <span class="token operator">=</span> read_list<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span>

<span class="token comment"># You can also specify fields</span>
fields <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;title&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span><span class="token punctuation">]</span>
df <span class="token operator">=</span> read_list<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> fields<span class="token operator">=</span>fields<span class="token punctuation">)</span>

<span class="token comment"># You can also return a list of dictionaries instead of a DataFrame</span>
data <span class="token operator">=</span> read_list<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> as_dataframe<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="extracting-article-content" tabindex="-1"><a class="header-anchor" href="#extracting-article-content" aria-hidden="true">#</a> Extracting Article Content</h3><p>Here is an example of how to use the SDK to extract article content from a webpage:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> crawlab_ai <span class="token keyword">import</span> read_article

<span class="token comment"># Define the URL</span>
url <span class="token operator">=</span> <span class="token string">&quot;https://example.com&quot;</span>

<span class="token comment"># Get the data</span>
data <span class="token operator">=</span> read_article<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="scrapy-integration" tabindex="-1"><a class="header-anchor" href="#scrapy-integration" aria-hidden="true">#</a> Scrapy Integration</h3>`,31),k={href:"https://scrapy.org",target:"_blank",rel:"noopener noreferrer"},g=t(`<p>You can start by creating a Scrapy spider that inherits from <code>ScrapyListSpider</code>:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> crawlab_ai <span class="token keyword">import</span> ScrapyListSpider

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>ScrapyListSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;my_spider&quot;</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;https://example.com&quot;</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>And that&#39;s it! You don&#39;t have to write any additional code to extract content from the webpage. The SDK will take care of the rest.</p><p>If you would like to specify the fields to extract, you can do so by overriding the <code>fields</code> attribute in your spider:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> crawlab_ai <span class="token keyword">import</span> ScrapyListSpider

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>ScrapyListSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;my_spider&quot;</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;https://example.com&quot;</span><span class="token punctuation">]</span>
    fields <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;title&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Then, you can run the spider using the following command:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>scrapy crawl my_spider
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,7);function f(w,y){const s=r("ExternalLinkIcon"),o=r("RouterLink");return l(),p("div",null,[u,n("p",null,[n("a",h,[a("Crawlab AI"),e(s)]),a(" provides an SDK for users to integrate Crawlab AI into their own applications. The SDK is now available in Python.")]),m,n("p",null,[a("To use the SDK, users need to obtain an "),e(o,{to:"/en/ai/api-token.html"},{default:i(()=>[a("API token")]),_:1}),a(" from the Crawlab AI platform. The API token is used to authenticate the requests made by the SDK. Users can obtain the API token by signing up for an account on the Crawlab "),n("a",b,[a("official site"),e(s)]),a(". You need to make sure you have a valid "),e(o,{to:"/en/ai/license.html"},{default:i(()=>[a("license")]),_:1}),a(" to use the API.")]),v,n("p",null,[a("You can also integrate the SDK with "),n("a",k,[a("Scrapy"),e(s)]),a(" to extract content from webpages.")]),g])}const _=c(d,[["render",f],["__file","sdk.html.vue"]]);export{_ as default};
