import{_ as l,Z as o,$ as c,a0 as s,a1 as a,a2 as n,a3 as r,a4 as t,G as p}from"./framework-1b68163c.js";const d={},u=s("h1",{id:"crawlab-ai-sdk",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#crawlab-ai-sdk","aria-hidden":"true"},"#"),a(" Crawlab AI SDK")],-1),v={href:"https://www.crawlab.cn/zh/ai",target:"_blank",rel:"noopener noreferrer"},m=t(`<h2 id="安装" tabindex="-1"><a class="header-anchor" href="#安装" aria-hidden="true">#</a> 安装</h2><p>用户可以使用以下命令安装SDK：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>pip <span class="token function">install</span> crawlab-ai
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="认证" tabindex="-1"><a class="header-anchor" href="#认证" aria-hidden="true">#</a> 认证</h2>`,4),h={href:"https://www.crawlab.cn/zh",target:"_blank",rel:"noopener noreferrer"},k=t(`<p>一旦你获取了API密钥，你可以在你的应用程序中将它设置为环境变量：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">CRAWLAB_TOKEN</span><span class="token operator">=</span><span class="token operator">&lt;</span>your-api-token<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>或者，你可以用CLI设置它：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai config <span class="token parameter variable">-t</span> <span class="token operator">&lt;</span>your-api-token<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="作为cli使用" tabindex="-1"><a class="header-anchor" href="#作为cli使用" aria-hidden="true">#</a> 作为CLI使用</h2><p>SDK可以作为命令行接口（CLI）工具使用。CLI工具提供了一组命令来与Crawlab AI平台交互。</p><h3 id="爬取网页" tabindex="-1"><a class="header-anchor" href="#爬取网页" aria-hidden="true">#</a> 爬取网页</h3><p>你可以使用SDK作为CLI来爬取网页，如下所示：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai crawl <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>-t <span class="token punctuation">{</span>article,list<span class="token punctuation">}</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>-o OUTPUT<span class="token punctuation">]</span> <span class="token operator">&lt;</span>url<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><code>-t</code>选项指定要提取的内容类型，可以是<code>article</code>或<code>list</code>。<code>-o</code>选项指定提取内容的输出路径。对于<code>article</code> 类型，输出将以JSON格式，而对于<code>list</code>，输出类型将以CSV。如果未指定输出路径，内容将打印到控制台。</p><p>例如，要从网页提取文章，你可以运行以下命令：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai crawl <span class="token parameter variable">-t</span> article https://www.example.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>要从网页提取项目列表，你可以运行以下命令：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai crawl <span class="token parameter variable">-t</span> list <span class="token parameter variable">-o</span> output.csv https://www.example.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="代码生成" tabindex="-1"><a class="header-anchor" href="#代码生成" aria-hidden="true">#</a> 代码生成</h3><p>你可以使用SDK作为CLI来生成从网页提取内容的代码片段，如下所示：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai codegen <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>-t <span class="token punctuation">{</span>article,list<span class="token punctuation">}</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>-o OUTPUT<span class="token punctuation">]</span> <span class="token operator">&lt;</span>url<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><code>-t</code>选项指定要提取的内容类型，可以是<code>article</code>或<code>list</code>。<code>-o</code>选项指定生成代码的输出路径。如果未指定输出路径，代码将打印到控制台。</p><p>例如，要生成从网页提取文章的代码，你可以运行以下命令：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai codegen <span class="token parameter variable">-t</span> article https://www.example.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>要生成从网页提取项目列表的代码，你可以运行以下命令：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>crawlab-ai codegen <span class="token parameter variable">-t</span> list <span class="token parameter variable">-o</span> output.py https://www.example.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="作为python库使用" tabindex="-1"><a class="header-anchor" href="#作为python库使用" aria-hidden="true">#</a> 作为Python库使用</h2><p>你也可以在你的应用程序中作为Python库使用SDK。</p><h3 id="提取列表内容" tabindex="-1"><a class="header-anchor" href="#提取列表内容" aria-hidden="true">#</a> 提取列表内容</h3><p>以下是如何使用SDK从网页提取列表内容的示例：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> crawlab_ai <span class="token keyword">import</span> read_list

<span class="token comment"># 定义URL</span>
url <span class="token operator">=</span> <span class="token string">&quot;https://example.com&quot;</span>

<span class="token comment"># 获取数据，不指定字段</span>
df <span class="token operator">=</span> read_list<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span>

<span class="token comment"># 你也可以指定字段</span>
fields <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;title&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span><span class="token punctuation">]</span>
df <span class="token operator">=</span> read_list<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> fields<span class="token operator">=</span>fields<span class="token punctuation">)</span>

<span class="token comment"># 你也可以返回字典列表，而不是DataFrame</span>
data <span class="token operator">=</span> read_list<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> as_dataframe<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="提取文章内容" tabindex="-1"><a class="header-anchor" href="#提取文章内容" aria-hidden="true">#</a> 提取文章内容</h3><p>以下是如何使用SDK从网页提取文章内容的示例：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> crawlab_ai <span class="token keyword">import</span> read_article

<span class="token comment"># 定义URL</span>
url <span class="token operator">=</span> <span class="token string">&quot;https://example.com&quot;</span>

<span class="token comment"># 获取数据</span>
data <span class="token operator">=</span> read_article<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="scrapy集成" tabindex="-1"><a class="header-anchor" href="#scrapy集成" aria-hidden="true">#</a> Scrapy集成</h3>`,31),b={href:"https://scrapy.org",target:"_blank",rel:"noopener noreferrer"},g=t(`<p>你可以开始创建一个继承自<code>ScrapyListSpider</code>的Scrapy spider：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> crawlab_ai <span class="token keyword">import</span> ScrapyListSpider

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>ScrapyListSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;my_spider&quot;</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;https://example.com&quot;</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>就这样轻松！你不必编写任何额外的代码来从网页提取内容。SDK将负责剩下的部分。</p><p>如果你想指定要提取的字段，你可以通过在你的spider中覆盖<code>fields</code>属性来实现：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> crawlab_ai <span class="token keyword">import</span> ScrapyListSpider

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>ScrapyListSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;my_spider&quot;</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;https://example.com&quot;</span><span class="token punctuation">]</span>
    fields <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;title&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>然后，你可以使用以下命令运行spider：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>scrapy crawl my_spider
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,7);function w(_,y){const e=p("ExternalLinkIcon"),i=p("RouterLink");return o(),c("div",null,[u,s("p",null,[s("a",v,[a("Crawlab AI"),n(e)]),a("为用户提供了一个SDK，用户可以将Crawlab AI集成到他们自己的应用程序中。SDK现在可以在Python中使用。")]),m,s("p",null,[a("要使用SDK，用户需要从Crawlab AI平台获取API密钥。API密钥用于验证SDK发出的请求。用户可以通过在Crawlab "),s("a",h,[a("官方网站"),n(e)]),a("上注册账户来获取API密钥。 你需要保证你有一个有效的"),n(i,{to:"/zh/ai/license.html"},{default:r(()=>[a("许可证")]),_:1}),a("来使用API。")]),k,s("p",null,[a("你也可以将SDK与"),s("a",b,[a("Scrapy"),n(e)]),a("集成，从网页提取内容。")]),g])}const x=l(d,[["render",w],["__file","sdk.html.vue"]]);export{x as default};
